{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "import pickle\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "import operator\n",
    "import threading\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sol import SOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "#from models import ResearchModels\n",
    "#from data import DataSet\n",
    "import time\n",
    "import os.path\n",
    "import numpy\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "\n",
    "from keras.layers import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "from keras.layers import Activation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from tensorflow.python.util.tf_export import tf_export\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import kerastuner as kt\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "from collections import deque\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Functions for evaluation metrics\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cm_tss(y_true,y_pred):\n",
    "    cm = confusion_matrix(np.argmax(y_true,axis=1),np.argmax(y_pred,axis=1))\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "\n",
    "    if TP + FN == 0.:\n",
    "        if TP == 0.:\n",
    "            tss_aux1 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux1 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux1 = (TP / (TP + FN))\n",
    "\n",
    "    if (FP + TN) == 0.:\n",
    "        if FP == 0.:\n",
    "            tss_aux2 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux2 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux2 = (FP / (FP + TN))\n",
    "\n",
    "    tss = tss_aux1 - tss_aux2\n",
    "    return cm,tss\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "def cm_tss_binary(y_true,y_pred):\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "\n",
    "    if TP + FN == 0.:\n",
    "        if TP == 0.:\n",
    "            tss_aux1 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux1 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux1 = (TP / (TP + FN))\n",
    "\n",
    "    if (FP + TN) == 0.:\n",
    "        if FP == 0.:\n",
    "            tss_aux2 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux2 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux2 = (FP / (FP + TN))\n",
    "\n",
    "    tss = tss_aux1 - tss_aux2\n",
    "    return cm,tss\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "def compute_tss(TP,TN,FP,FN):\n",
    "    tss = numpy.zeros(TP.shape[0])\n",
    "    for i in range(TP.shape[0]):\n",
    "        if TP[i]+FN[i] == 0.:\n",
    "            if TP[i] == 0.:\n",
    "                tss_aux1 = 0.  # float('NaN')\n",
    "            else:\n",
    "                tss_aux1 = -100 \n",
    "        else:\n",
    "            tss_aux1 = (TP[i] / (TP[i] + FN[i]))\n",
    "            \n",
    "        if FP[i]+TN[i] == 0.:\n",
    "            if FP[i] == 0.:\n",
    "                tss_aux2 = 0.  # float('NaN')\n",
    "            else:\n",
    "                tss_aux2 = -100 \n",
    "        else:\n",
    "            tss_aux2 = (FP[i] / (FP[i] + TN[i]))\n",
    "        \n",
    "        tss[i] = tss_aux1 - tss_aux2\n",
    "    \n",
    "    return tss\n",
    "\n",
    "######################################################################################\n",
    "# Correzione a posteriori per metrica myTP, myTN etc etc\n",
    "\n",
    "def compute_tss_cat_ce(TP,TN,FP,FN,steps_per_epoch):\n",
    "    TP=np.round(TP*steps_per_epoch)\n",
    "    FP=np.round(FP*steps_per_epoch)\n",
    "    TN=np.round(TN*steps_per_epoch)\n",
    "    FN=np.round(FN*steps_per_epoch)\n",
    "    tss = numpy.zeros(TP.shape[0])\n",
    "    for i in range(TP.shape[0]):\n",
    "        if TP[i]+FN[i] == 0.:\n",
    "            if TP[i] == 0.:\n",
    "                tss_aux1 = 0.  # float('NaN')\n",
    "            else:\n",
    "                tss_aux1 = -100 \n",
    "        else:\n",
    "            tss_aux1 = (TP[i] / (TP[i] + FN[i]))\n",
    "            \n",
    "        if FP[i]+TN[i] == 0.:\n",
    "            if FP[i] == 0.:\n",
    "                tss_aux2 = 0.  # float('NaN')\n",
    "            else:\n",
    "                tss_aux2 = -100 \n",
    "        else:\n",
    "            tss_aux2 = (FP[i] / (FP[i] + TN[i]))\n",
    "        \n",
    "        tss[i] = tss_aux1 - tss_aux2\n",
    "    \n",
    "    return tss\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "def tss(y_true,y_pred):\n",
    "\n",
    "    cm = confusion_matrix(numpy.argmax(y_true,axis=1),numpy.argmax(y_pred,axis=1))\n",
    "\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "\n",
    "        a = 0.\n",
    "\n",
    "        d = float(cm[0, 0])\n",
    "\n",
    "        b = 0.\n",
    "\n",
    "        c = 0.\n",
    "\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "\n",
    "        a = float(cm[0, 0])\n",
    "\n",
    "        d = 0.\n",
    "\n",
    "        b = 0.\n",
    "\n",
    "        c = 0.\n",
    "\n",
    "    elif cm.shape[0] == 2:\n",
    "\n",
    "        a = float(cm[1, 1])\n",
    "\n",
    "        d = float(cm[0, 0])\n",
    "\n",
    "        b = float(cm[0, 1])\n",
    "\n",
    "        c = float(cm[1, 0])\n",
    "\n",
    "    TP = a\n",
    "\n",
    "    TN = d\n",
    "\n",
    "    FP = b\n",
    "\n",
    "    FN = c\n",
    "\n",
    "\n",
    "\n",
    "    if TP + FN == 0.:\n",
    "\n",
    "        if TP == 0.:\n",
    "\n",
    "            tss_aux1 = 0.  # float('NaN')\n",
    "\n",
    "        else:\n",
    "\n",
    "            tss_aux1 = -100  # float('Inf')\n",
    "\n",
    "    else:\n",
    "\n",
    "        tss_aux1 = (TP / (TP + FN))\n",
    "\n",
    "\n",
    "\n",
    "    if (FP + TN) == 0.:\n",
    "\n",
    "        if FP == 0.:\n",
    "\n",
    "            tss_aux2 = 0.  # float('NaN')\n",
    "\n",
    "        else:\n",
    "\n",
    "            tss_aux2 = -100  # float('Inf')\n",
    "\n",
    "    else:\n",
    "\n",
    "        tss_aux2 = (FP / (FP + TN))\n",
    "\n",
    "\n",
    "\n",
    "    tss = tss_aux1 - tss_aux2\n",
    "\n",
    "    return tss\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "def hss(y_true,y_pred):\n",
    "\n",
    "    cm = confusion_matrix(numpy.argmax(y_true,axis=1),numpy.argmax(y_pred,axis=1))\n",
    "\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "\n",
    "        a = 0.\n",
    "\n",
    "        d = float(cm[0, 0])\n",
    "\n",
    "        b = 0.\n",
    "\n",
    "        c = 0.\n",
    "\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "\n",
    "        a = float(cm[0, 0])\n",
    "\n",
    "        d = 0.\n",
    "\n",
    "        b = 0.\n",
    "\n",
    "        c = 0.\n",
    "\n",
    "    elif cm.shape[0] == 2:\n",
    "\n",
    "        a = float(cm[1, 1])\n",
    "\n",
    "        d = float(cm[0, 0])\n",
    "\n",
    "        b = float(cm[0, 1])\n",
    "\n",
    "        c = float(cm[1, 0])\n",
    "\n",
    "    TP = a\n",
    "\n",
    "    TN = d\n",
    "\n",
    "    FP = b\n",
    "\n",
    "    FN = c\n",
    "\n",
    "\n",
    "\n",
    "    if ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN)) == 0.:\n",
    "\n",
    "        if (TP * TN - FN * FP) == 0:\n",
    "\n",
    "            hss = 0.  # float('NaN')\n",
    "\n",
    "        else:\n",
    "\n",
    "            hss = -100  # float('Inf')\n",
    "\n",
    "    else:\n",
    "\n",
    "        hss = 2 * (TP * TN - FN * FP) / ((TP + FN) *\n",
    "\n",
    "                                         (FN + TN) + (TP + FP) * (FP + TN))\n",
    "\n",
    "    return hss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for choosing the best threshold\n",
    "\n",
    "def optimize_threshold_skill_scores(probability_prediction, Y_training):\n",
    "    n_samples = 100\n",
    "    step = 1. / n_samples\n",
    "    \n",
    "    xss = -1.\n",
    "    xss_threshold = 0\n",
    "    Y_best_predicted = numpy.zeros((Y_training.shape))\n",
    "    tss_vector = numpy.zeros(n_samples)\n",
    "    hss_vector = numpy.zeros(n_samples)\n",
    "    xss_threshold_vector = numpy.zeros(n_samples)\n",
    "    a = probability_prediction.max()\n",
    "    b = probability_prediction.min()\n",
    "    for threshold in range(1, n_samples):\n",
    "        xss_threshold = step * threshold * numpy.abs(a - b) + b\n",
    "        xss_threshold_vector[threshold] = xss_threshold\n",
    "        Y_predicted = probability_prediction > xss_threshold\n",
    "        res = metrics_classification(Y_training > 0, Y_predicted, print_skills=False)\n",
    "        tss_vector[threshold] = res['tss']\n",
    "        hss_vector[threshold] = res['hss']\n",
    "        \n",
    "    if numpy.max(tss_vector)==0.:\n",
    "        max_tss = numpy.max(tss_vector) + numpy.finfo(float).eps\n",
    "    else:\n",
    "        max_tss = numpy.max(tss_vector)\n",
    "        \n",
    "    if numpy.max(hss_vector)==0.:\n",
    "        max_hss = numpy.max(hss_vector) + numpy.finfo(float).eps\n",
    "    else:\n",
    "        max_hss = numpy.max(hss_vector)\n",
    "    \n",
    "            \n",
    "    nss_vector = 0.5*((tss_vector/max_tss) + (hss_vector/max_hss))\n",
    "\n",
    "    idx_best_nss = numpy.where(nss_vector==numpy.max(nss_vector))  \n",
    "    print('idx best nss=',idx_best_nss)\n",
    "    #best NSS\n",
    "    best_xss_threshold = xss_threshold_vector[idx_best_nss]\n",
    "    if len(best_xss_threshold)>1:\n",
    "        best_xss_threshold = best_xss_threshold[0]\n",
    "        Y_best_predicted = probability_prediction > best_xss_threshold\n",
    "    else:\n",
    "        Y_best_predicted = probability_prediction > best_xss_threshold\n",
    "    print('best NSS')\n",
    "    metrics_training = metrics_classification(Y_training > 0, Y_best_predicted)\n",
    "    \n",
    "    #best TSS\n",
    "    idx_best_tss = numpy.where(tss_vector==numpy.max(tss_vector))  \n",
    "    print('idx best tss=',idx_best_tss)\n",
    "    best_xss_threshold_tss = xss_threshold_vector[idx_best_tss]\n",
    "    if len(best_xss_threshold_tss)>1:\n",
    "        best_xss_threshold_tss = best_xss_threshold_tss[0]\n",
    "        Y_best_predicted_tss = probability_prediction > best_xss_threshold_tss\n",
    "    else:\n",
    "        Y_best_predicted_tss = probability_prediction > best_xss_threshold_tss\n",
    "    print('best TSS')\n",
    "    metrics_training_tss = metrics_classification(Y_training > 0, Y_best_predicted_tss)\n",
    "    \n",
    "    #best HSS\n",
    "    idx_best_hss = numpy.where(hss_vector==numpy.max(hss_vector))  \n",
    "    print('idx best hss=',idx_best_hss)\n",
    "    best_xss_threshold_hss = xss_threshold_vector[idx_best_hss]\n",
    "    if len(best_xss_threshold_hss)>1:\n",
    "        best_xss_threshold_hss = best_xss_threshold_hss[0]\n",
    "        Y_best_predicted_hss = probability_prediction > best_xss_threshold_hss\n",
    "    else:\n",
    "        Y_best_predicted_hss = probability_prediction > best_xss_threshold_hss\n",
    "    print('best HSS')\n",
    "    metrics_training_hss = metrics_classification(Y_training > 0, Y_best_predicted_hss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #best (TSS+HSS)/2\n",
    "    comb_tss_hss = (hss_vector+tss_vector)/2.\n",
    "    idx_best_tss_hss = numpy.where(comb_tss_hss==numpy.max(comb_tss_hss)) \n",
    "    print('idx best (tss+hss)/2 =',idx_best_tss_hss)\n",
    "    best_xss_threshold_tss_hss = xss_threshold_vector[idx_best_tss_hss]\n",
    "    if len(best_xss_threshold_tss_hss)>1:\n",
    "        best_xss_threshold_tss_hss = best_xss_threshold_tss_hss[0]\n",
    "        Y_best_predicted_tss_hss = probability_prediction > best_xss_threshold_tss_hss\n",
    "    else:\n",
    "        Y_best_predicted_tss_hss = probability_prediction > best_xss_threshold_tss_hss\n",
    "    print('best (TSS+HSS)/2')\n",
    "    metrics_training_tss_hss = metrics_classification(Y_training > 0, Y_best_predicted_tss_hss)\n",
    "    \n",
    "   \n",
    "\n",
    "    return best_xss_threshold, metrics_training, nss_vector, best_xss_threshold_tss, best_xss_threshold_hss,best_xss_threshold_tss_hss\n",
    "\n",
    "def metrics_classification(y_real, y_pred, print_skills=True):\n",
    "\n",
    "    cm, far, pod, acc, hss, tss, fnfp, csi = classification_skills(y_real, y_pred)\n",
    "\n",
    "    if print_skills:\n",
    "        print ('confusion matrix')\n",
    "        print (cm)\n",
    "        print ('false alarm ratio       \\t', far)\n",
    "        print ('probability of detection\\t', pod)\n",
    "        print ('accuracy                \\t', acc)\n",
    "        print ('hss                     \\t', hss)\n",
    "        print ('tss                     \\t', tss)\n",
    "        print ('balance                 \\t', fnfp)\n",
    "        print ('csi                 \\t', csi)\n",
    "\n",
    "    balance_label = float(sum(y_real)) / y_real.shape[0]\n",
    "\n",
    "    #cm, far, pod, acc, hss, tss, fnfp = classification_skills(y_real, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"cm\": cm,\n",
    "        \"far\": far,\n",
    "        \"pod\": pod,\n",
    "        \"acc\": acc,\n",
    "        \"hss\": hss,\n",
    "        \"tss\": tss,\n",
    "        \"fnfp\": fnfp,\n",
    "        \"balance label\": balance_label,\n",
    "        \"csi\": csi}\n",
    "\n",
    "def classification_skills(y_real, y_pred):\n",
    "\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "\n",
    "    if cm.shape[0] == 1 and sum(y_real) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_real) == y_real.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "\n",
    "    if (TP + FP + FN + TN) == 0.:\n",
    "        if (TP + TN) == 0.:\n",
    "            acc = 0.  # float('NaN')\n",
    "        else:\n",
    "            acc = -100  # float('Inf')\n",
    "    else:\n",
    "        acc = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "    if TP + FN == 0.:\n",
    "        if TP == 0.:\n",
    "            tss_aux1 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux1 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux1 = (TP / (TP + FN))\n",
    "\n",
    "    if (FP + TN) == 0.:\n",
    "        if FP == 0.:\n",
    "            tss_aux2 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux2 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux2 = (FP / (FP + TN))\n",
    "\n",
    "    tss = tss_aux1 - tss_aux2\n",
    "\n",
    "    if ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN)) == 0.:\n",
    "        if (TP * TN - FN * FP) == 0:\n",
    "            hss = 0.  # float('NaN')\n",
    "        else:\n",
    "            hss = -100  # float('Inf')\n",
    "    else:\n",
    "        hss = 2 * (TP * TN - FN * FP) / ((TP + FN) *\n",
    "                                         (FN + TN) + (TP + FP) * (FP + TN))\n",
    "\n",
    "    if FP == 0.:\n",
    "        if FN == 0.:\n",
    "            fnfp = 0.  # float('NaN')\n",
    "        else:\n",
    "            fnfp = -100  # float('Inf')\n",
    "    else:\n",
    "        fnfp = FN / FP\n",
    "\n",
    "    if (TP + FN) == 0.:\n",
    "        if TP == 0.:\n",
    "            pod = 0  # float('NaN')\n",
    "        else:\n",
    "            pod = -100  # float('Inf')\n",
    "    else:\n",
    "        pod = TP / (TP + FN)\n",
    "\n",
    "\n",
    "    if (TP + FP) == 0.:\n",
    "        if FP == 0.:\n",
    "            far = 0.  # float('NaN')\n",
    "        else:\n",
    "            far = -100  # float('Inf')\n",
    "    else:\n",
    "        far = FP / (TP + FP)\n",
    "\n",
    "    #acc = (a + d) / (a + b + c + d)\n",
    "    #tpr = a / (a + b)\n",
    "    #tnr = d / (d + c)\n",
    "    #wtpr = a / (a + b) * (a + c) / (a + b + c + d) + d / (c + d) * (b + d) / (a + b + c + d)\n",
    "    #pacc = a / (a + c)\n",
    "    #nacc = d / (b + d)\n",
    "    #wacc = a / (a + c) * (a + c) / (a + b + c + d) + d / (b + d) * (b + d) / (a + b + c + d)\n",
    "\n",
    "    # if the cm has a row or a column equal to 0, we have bad tss\n",
    "    if TP+FN == 0 or TN+FP == 0 or TP+FP == 0 or TN+FN == 0:\n",
    "        tss = 0\n",
    "    if TP+FP+FN==0:\n",
    "        csi = 0\n",
    "    else:\n",
    "        csi = TP/(TP+FP+FN)\n",
    "\n",
    "    #, pod, acc, hss, tss, fnfp, tpr, tnr, pacc, nacc, wacc, wtpr)\n",
    "    return cm.tolist(), far, pod, acc, hss, tss, fnfp, csi\n",
    "\n",
    "def compute_cm_tss_threshold(y, pred,threshold):\n",
    "    # Compute confusion matrix and TSS given y_true and y_pred in categorical form\n",
    "    pred_threshold = pred > threshold\n",
    "    cm = confusion_matrix(y,pred_threshold)\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "\n",
    "    if TP + FN == 0.:\n",
    "        if TP == 0.:\n",
    "            tss_aux1 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux1 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux1 = (TP / (TP + FN))\n",
    "\n",
    "    if (FP + TN) == 0.:\n",
    "        if FP == 0.:\n",
    "            tss_aux2 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux2 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux2 = (FP / (FP + TN))\n",
    "\n",
    "    tss = tss_aux1 - tss_aux2\n",
    "    \n",
    "    if ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN)) == 0.:\n",
    "        if (TP * TN - FN * FP) == 0:\n",
    "            hss = 0.  # float('NaN')\n",
    "        else:\n",
    "            hss = -100  # float('Inf')\n",
    "    else:\n",
    "        hss = 2 * (TP * TN - FN * FP) / ((TP + FN) *\n",
    "                                         (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    \n",
    "    if TP+FP+FN==0:\n",
    "        CSI = 0\n",
    "    else:\n",
    "        CSI = TP/(TP+FP+FN)\n",
    "\n",
    "    \n",
    "    return cm, tss, hss, CSI\n",
    "        \n",
    "    \n",
    "def compute_cm_tss(y, pred):\n",
    "    # Compute confusion matrix and TSS given y_true and y_pred in categorical form\n",
    "    cm = confusion_matrix(y,pred)\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "\n",
    "    if TP + FN == 0.:\n",
    "        if TP == 0.:\n",
    "            tss_aux1 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux1 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux1 = (TP / (TP + FN))\n",
    "\n",
    "    if (FP + TN) == 0.:\n",
    "        if FP == 0.:\n",
    "            tss_aux2 = 0.  # float('NaN')\n",
    "        else:\n",
    "            tss_aux2 = -100  # float('Inf')\n",
    "    else:\n",
    "        tss_aux2 = (FP / (FP + TN))\n",
    "\n",
    "    tss = tss_aux1 - tss_aux2\n",
    "    \n",
    "    if ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN)) == 0.:\n",
    "        if (TP * TN - FN * FP) == 0:\n",
    "            hss = 0.  # float('NaN')\n",
    "        else:\n",
    "            hss = -100  # float('Inf')\n",
    "    else:\n",
    "        hss = 2 * (TP * TN - FN * FP) / ((TP + FN) *\n",
    "                                         (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    \n",
    "    if TP+FP+FN==0:\n",
    "        CSI = 0\n",
    "    else:\n",
    "        CSI = TP/(TP+FP+FN)\n",
    "\n",
    "    \n",
    "    return cm, tss, hss, CSI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "General functions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        return np.nan\n",
    "    else: \n",
    "        return a/b\n",
    "\n",
    "acc = lambda TN,FP,FN,TP: np.nan_to_num(divide(TP+TN,TN+FP+FN+TP))\n",
    "prec = lambda TN,FP,FN,TP: np.nan_to_num(divide(TP,FP+TP))\n",
    "rec = lambda TN,FP,FN,TP: np.nan_to_num(divide(TP,FN+TP))\n",
    "spec = lambda TN,FP,FN,TP: np.nan_to_num(divide(TN,FP+TN))\n",
    "f1s = lambda TN,FP,FN,TP: 2.*np.nan_to_num(divide(prec(TN,FP,FN,TP)*\\\n",
    "                          rec(TN,FP,FN,TP),prec(TN,FP,FN,TP)+rec(TN,FP,FN,TP)))\n",
    "tss = lambda TN,FP,FN,TP: rec(TN,FP,FN,TP)+spec(TN,FP,FN,TP)-1.\n",
    "csi = lambda TN,FP,FN,TP: np.nan_to_num(divide(TP,FN+FP+TP))\n",
    "hss1 = lambda TN,FP,FN,TP: np.nan_to_num(divide(TP-FP,FN+TP))\n",
    "hss2 = lambda TN,FP,FN,TP: np.nan_to_num(divide((2.*((TP*TN)-(FP*FN))),((TP+FN)\\\n",
    "                            *(FN+TN))+((TP+FP)*(TN+FP))))\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "def cm_score_binary(y_true,y_pred,thresh,score):\n",
    "    y_pred = np.array([0 if y_pred[i]<thresh else 1 for i in range(0,len(y_pred))])\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "    \n",
    "    if score == 'accuracy':\n",
    "        score = acc\n",
    "    if score == 'precision':\n",
    "        score = prec\n",
    "    if score == 'recall':\n",
    "        score = rec    \n",
    "    if score == 'specificity':\n",
    "        score = spec        \n",
    "    if score == 'f1_score':\n",
    "        score = f1s\n",
    "    if score == 'tss':\n",
    "        score = tss\n",
    "    if score == 'csi':\n",
    "        score = csi\n",
    "    if score == 'hss1':\n",
    "        score = hss1        \n",
    "    if score == 'hss2':\n",
    "        score = hss2 \n",
    "    \n",
    "\n",
    "\n",
    "    return cm,score(TN,FP,FN,TP)\n",
    "\n",
    "def score_training(y_true,y_pred):\n",
    "    \n",
    "    thresh = 0.5\n",
    "    score = 'tss'\n",
    "    \n",
    "    y_true = y_true.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "    \n",
    "    y_pred = np.array([0 if y_pred[i]<thresh else 1 for i in range(0,len(y_pred))])\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "    \n",
    "    if cm.shape[0] == 1 and sum(y_true) == 0:\n",
    "        a = 0.\n",
    "        d = float(cm[0, 0])\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 1 and sum(y_true) == y_true.shape[0]:\n",
    "        a = float(cm[0, 0])\n",
    "        d = 0.\n",
    "        b = 0.\n",
    "        c = 0.\n",
    "    elif cm.shape[0] == 2:\n",
    "        a = float(cm[1, 1])\n",
    "        d = float(cm[0, 0])\n",
    "        b = float(cm[0, 1])\n",
    "        c = float(cm[1, 0])\n",
    "    TP = a\n",
    "    TN = d\n",
    "    FP = b\n",
    "    FN = c\n",
    "    \n",
    "    if score == 'accuracy':\n",
    "        score = acc\n",
    "    if score == 'precision':\n",
    "        score = prec\n",
    "    if score == 'recall':\n",
    "        score = rec    \n",
    "    if score == 'specificity':\n",
    "        score = spec        \n",
    "    if score == 'f1_score':\n",
    "        score = f1s\n",
    "    if score == 'tss':\n",
    "        score = tss\n",
    "    if score == 'csi':\n",
    "        score = csi\n",
    "    if score == 'hss1':\n",
    "        score = hss1        \n",
    "    if score == 'hss2':\n",
    "        score = hss2 \n",
    "\n",
    "    return score(TN,FP,FN,TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the variables of input shape\n",
    "\n",
    "#number of images in time series\n",
    "seq_length = 40\n",
    "#size of images\n",
    "number_channels = 1\n",
    "image_shape = (128,128,number_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LRCN MODEL\n",
    "\n",
    "# the input shape is composed by (number of images in time series, image height, image width, number of channels)\n",
    "\n",
    "#in the case no multi channel data are used set number_of_channels equal to 1\n",
    "\n",
    "input_shape = (seq_length, image_shape[0], image_shape[1], number_channels)\n",
    "\n",
    "initialiser = 'glorot_uniform'\n",
    "\n",
    "reg_lambda  = 0.01\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# first block\n",
    "model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same',kernel_regularizer=regularizers.l2(reg_lambda),\n",
    "                                               kernel_initializer=initialiser) , \n",
    "                                  input_shape=input_shape)) \n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\n",
    "\n",
    "# second block\n",
    "model.add(TimeDistributed(Conv2D(32, (5, 5), strides=(2, 2), padding='same',kernel_regularizer=regularizers.l2(reg_lambda),\n",
    "                                               kernel_initializer=initialiser), \n",
    "                                  input_shape=self.input_shape)) \n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\n",
    "\n",
    "# third block\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), strides=(2, 2), padding='same',kernel_regularizer=regularizers.l2(reg_lambda),\n",
    "                                               kernel_initializer=initialiser), \n",
    "                                  input_shape=self.input_shape))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\n",
    "\n",
    "# fourth block\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), strides=(2, 2), padding='same',kernel_regularizer=regularizers.l2(reg_lambda),\n",
    "                                               kernel_initializer=initialiser), \n",
    "                                  input_shape=self.input_shape)) \n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\n",
    "        \n",
    "        \n",
    "# MLP\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(64,activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.1)))\n",
    "\n",
    "#LSTM\n",
    "model.add(LSTM(50, return_sequences=False, dropout=0.5)) #50 100 256\n",
    "\n",
    "#output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-4, decay=1e-6)\n",
    "\n",
    "loss = SOL(score='tss',distribution='uniform', mu=0.5, delta=0.1)\n",
    "\n",
    "metrics = [score_training]\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer,metrics=metrics, run_eagerly=True)\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "def decay_schedule(epoch, lr):\n",
    "    # decay by 0.1 every 5 epochs; use `% 1` to decay after each epoch\n",
    "    if (epoch % 10 == 0) and (epoch != 0):\n",
    "        lr = lr / 2.\n",
    "    return lr\n",
    "\n",
    "# Function for training the deep neural network\n",
    "def train_uniform(model, seq_length, model_name,data_type, X_train_file,y_train_file,X_val_file, y_val_file,\n",
    "                   saved_model=None,\n",
    "          class_limit=None, image_shape=None,\n",
    "          load_to_memory=True, batch_size=32, nb_epoch=100,cl='C',fold=1):\n",
    "\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=os.path.join('data', 'checkpoints', model + '-' + data_type + '-'+\\\n",
    "                              '_tss_loss_ten_fold_uniform_classes_aug_discard_24h_'+cl+'_'+str(fold)+'_lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4_'+str(batch_size)+'batch_'+str(nb_epoch)+'epoch' \\\n",
    "            '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_best_only=False) #\n",
    "   \n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=1000)\n",
    "    lr_scheduler = LearningRateScheduler(decay_schedule)\n",
    "    # Helper: Save results.\n",
    "    timestamp = time.time()\n",
    "    csv_logger = CSVLogger(os.path.join('data', 'logs', model + '-' + 'training-' + \\\n",
    "        str(timestamp) + '.log'))\n",
    "    \n",
    "\n",
    "    X_train = np.load(X_train_file)/4000.\n",
    "    y_train = np.load(y_train_file).astype(numpy.float32)\n",
    "    \n",
    "    X_val = np.load(X_val_file)/4000.\n",
    "    y_val = np.load(y_val_file).astype(numpy.float32)\n",
    "  \n",
    "    X_train,y_train = sklearn.utils.shuffle(X_train,y_train,random_state=42)\n",
    "    X_train,y_train = sklearn.utils.shuffle(X_train,y_train,random_state=42)\n",
    "    X_train,y_train = sklearn.utils.shuffle(X_train,y_train,random_state=42)\n",
    "    \n",
    "    X_val,y_val = sklearn.utils.shuffle(X_val,y_val,random_state=42)\n",
    "    X_val,y_val = sklearn.utils.shuffle(X_val,y_val,random_state=42)\n",
    "    X_val,y_val = sklearn.utils.shuffle(X_val,y_val,random_state=42)\n",
    "\n",
    "    dim_y_train=y_train.shape[0]\n",
    "    \n",
    "    dim_y_val=y_val.shape[0]\n",
    "    \n",
    "    steps_per_epoch = dim_y_train//batch_size \n",
    "    validation_step = dim_y_val//batch_size\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[ early_stopper, csv_logger, checkpointer],#[early_stopper], #tb,, checkpointer csvlogger\n",
    "        epochs=nb_epoch)\n",
    "\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    rm.model.save('data/'+model+'_batch_'+str(batch_size)+'_epoch_'+str(nb_epoch)+\\\n",
    "                  '_tss_loss_ten_fold_uniform_classes_aug_discard_24h_'+cl+'_'+str(fold)+'_lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4.hdf5') #_weight_class\n",
    "    \n",
    "\n",
    "    a_file = open('data/'+model+'_history_batch_'+str(batch_size)+'_epoch_'+str(nb_epoch)+\\\n",
    "                  '_tss_loss_ten_fold_uniform_classes_aug_discard_24h_'+cl+'_'+str(fold)+'_lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4.pkl', \"wb\")\n",
    "    pickle.dump(rm.model.history.history, a_file)\n",
    "    a_file.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    return model #, metrics.get_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'lrcn_sol' \n",
    "saved_model = None  # None or weights file\n",
    "class_limit = None  # int, can be 1-101 or None\n",
    "\n",
    "load_to_memory = True  # pre-load the sequences into memory\n",
    "batch_size = 128\n",
    "nb_epoch = 100 \n",
    "data_type = 'images'\n",
    "\n",
    "\n",
    "cl='C'\n",
    "folder_data='data/'\n",
    "fold=1\n",
    "\n",
    "training_key = False\n",
    "\n",
    "#Train the deep neaural network given a training and validation set\n",
    "if training:\n",
    "    # Filenames of the training data\n",
    "    X_train_file = folder_data+'X_train_aug_fold_'+str(fold)+'.npy'#\n",
    "    y_train_file = folder_data+'Y_train_aug_'+cl+'_discard_fold_'+str(fold)+'.npy'\n",
    "\n",
    "    # Filenames of the validation data\n",
    "    X_val_file = folder_data+'X_validation_aug_discard_fold_'+str(fold)+'.npy'\n",
    "    y_val_file = folder_data+'Y_validation_aug_'+cl+'_discard_fold_'+str(fold)+'.npy'\n",
    "\n",
    "    model_history=train_uniform(model, seq_length, model_name,data_type, X_train_file,y_train_file,X_val_file, y_val_file,\n",
    "                    saved_model=saved_model,\n",
    "          class_limit=class_limit, image_shape=image_shape,\n",
    "          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch,cl=cl,fold=fold)\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,len(model_history.history.history[\"loss\"])), model_history.history.history[\"loss\"], label=\"train_loss\") #nb_epoch\n",
    "    plt.plot(np.arange(0, len(model_history.history.history[\"val_loss\"])), model_history.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Loss on Dataset\") #Training  and Accuracy\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\") #/Accuracy\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig('plot_'+model+'_loss_batch_'+str(batch_size)+'_epoch_'+str(nb_epoch)+\\\n",
    "            '_tss_loss_ten_fold_uniform_classes_aug_discard_24h_'+cl+'_'+str(fold)+'_lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4.png')\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,len(model_history.history.history[\"score_training\"])), model_history.history.history[\"score_training\"], label=\"train_score\") #nb_epoch\n",
    "    plt.plot(np.arange(0, len(model_history.history.history[\"val_score_training\"])), model_history.history.history[\"val_score_training\"], label=\"val_score\")\n",
    "    plt.title(\"Score on Dataset\") #Training  and Accuracy\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Score\") #/Accuracy\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig('plot_'+model+'_score_batch_'+str(batch_size)+'_epoch_'+str(nb_epoch)+\\\n",
    "            '_tss_loss_ten_fold_uniform_classes_aug_discard_24h_'+cl+'_'+str(fold)+'_lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation and test data\n",
    "import gc\n",
    "import sklearn\n",
    "\n",
    "cl='C'\n",
    "fold=1\n",
    "folder_data='data/'\n",
    "\n",
    "# Filenames of validation and test data\n",
    "X_test_file = folder_data+'X_test_discard_fold_'+str(fold)+'.npy'\n",
    "y_test_file = folder_data+'Y_test_'+cl+'_discard_fold_'+str(fold)+'.npy'\n",
    "\n",
    "X_test = np.load(X_test_file)/4000.\n",
    "y_test = np.load(y_test_file).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "X_val_file = folder_data+'X_validation_aug_discard_fold_'+str(fold)+'.npy'\n",
    "y_val_file = folder_data+'Y_validation_aug_'+cl+'_discard_fold_'+str(fold)+'.npy'\n",
    "  \n",
    "X_val = np.load(X_val_file)/4000.\n",
    "y_val = np.load(y_val_file).astype(np.float32)\n",
    "\n",
    "X_val,y_val = sklearn.utils.shuffle(X_val,y_val,random_state=42)\n",
    "X_val,y_val = sklearn.utils.shuffle(X_val,y_val,random_state=42)\n",
    "X_val,y_val = sklearn.utils.shuffle(X_val,y_val,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model accordingly to the highest TSS on the validation set and predict on the test set\n",
    "\n",
    "from pandas import read_pickle\n",
    "mod_hist=read_pickle('lrcn_sol_history_batch_'+str(batch_size)+'_epoch_'+str(nb_epoch)+'_tss_loss_ten_fold_uniform_all_classes_no_aug_discard_24h_'+cl+'_'+str(fold)+'_lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4.pkl')\n",
    "\n",
    "idx =np.where(mod_hist[\"val_score_training\"]==np.max(mod_hist[\"val_score_training\"]))\n",
    "\n",
    "print(idx)\n",
    "print(np.array(mod_hist[\"val_score_training\"])[idx])\n",
    "\n",
    "folder = 'checkpoints/'\n",
    "\n",
    "list_epochs = sorted(glob.glob(folder+'lrcn_sol-images-_tss_loss_ten_fold_uniform_all_classes_no_aug_discard_24h_'+cl+'_'+str(fold)+'_'+\\\n",
    "                               'lrcn_32kern_7_5_3_3_size_reg_dense_64_lstm_50_adam_lr_1e-4_'+str(batch_size)+'batch_'+str(nb_epoch)+'epoch*.hdf5'))\n",
    "print(len(list_epochs))\n",
    "\n",
    "model = load_model(list_epochs[idx[0][0]],compile=False)\n",
    "print(list_epochs[idx[0][0]])\n",
    "\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_prob_test = pred_test[:,0]#if use binary ce, tss loss..\n",
    "\n",
    "pred_prob_test = pred_prob_test.reshape(1,len(pred_prob_test))\n",
    "pred_prob_test = pred_prob_test[0]\n",
    "pred_0_1 = pred_prob_test > 0.5\n",
    "\n",
    "print('Case epoch with maximum tss_val and threshold=0.5')\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, pred_0_1)#_weight\n",
    "print('Skill scores (threshold=0.5)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))\n",
    "\n",
    "#####################################################################\n",
    "#choose the best threshold in validation with the best epoch \n",
    "\n",
    "pred_val = model.predict(X_val)\n",
    "gc.collect()\n",
    "\n",
    "pred_prob_val = pred_val[:,0]#if use binary crossentropy, tss loss ...\n",
    "\n",
    "#OPTIMIZE NSS, TSS, HSS, ..\n",
    "threshold_nss, metrics_training, nss_vector, threshold_tss, threshold_hss, threshold_tss_hss = \\\n",
    "                                     optimize_threshold_skill_scores(pred_prob_val, y_val)\n",
    "pred_0_1_opt_tss = pred_prob_test > threshold_tss\n",
    "\n",
    "print('Case epoch with maximum tss_val and optimum threshold')\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, pred_0_1_opt_tss)#_weight\n",
    "print('Skill scores (opt threshold)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))\n",
    "\n",
    "pred_0_1_test = pred_prob_test > 0.5\n",
    "\n",
    "print('Case epoch with maximum tss_val and threshold = 0.5')\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, pred_0_1_test)#_weight\n",
    "print('Skill scores (threshold = 0.5)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
